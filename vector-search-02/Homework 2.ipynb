{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "homework-title",
   "metadata": {},
   "source": [
    "# LLM Zoomcamp - Homework 2: Vector Search\n",
    "\n",
    "This notebook contains solutions for Homework 2 focusing on vector search implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q1-title",
   "metadata": {},
   "source": [
    "## Q1. Embedding the query\n",
    "\n",
    "Embed the query: 'I just discovered the course. Can I join now?'. Use the 'jinaai/jina-embeddings-v2-small-en' model.\n",
    "\n",
    "You should get a numpy array of size 512.\n",
    "\n",
    "What's the minimal value in this array?\n",
    "\n",
    "Options:\n",
    "- -0.51\n",
    "- -0.11\n",
    "- 0\n",
    "- 0.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q1-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "# pip install -q \"qdrant-client[fastembed]>=1.14.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "q1-solution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: I just discovered the course. Can I join now?\n",
      "Embedding shape: (512,)\n",
      "Minimal value: -0.11726373551188797\n",
      "Maximal value: 0.13307955253468784\n"
     ]
    }
   ],
   "source": [
    "# Q1 Solution: Embedding the query\n",
    "from fastembed import TextEmbedding\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the embedding model\n",
    "embedding_model = TextEmbedding(\"jinaai/jina-embeddings-v2-small-en\")\n",
    "\n",
    "# Embed the query\n",
    "query = \"I just discovered the course. Can I join now?\"\n",
    "query_embedding = list(embedding_model.embed([query]))[0]\n",
    "\n",
    "# Convert to numpy array\n",
    "query_vector = np.array(query_embedding)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Embedding shape: {query_vector.shape}\")\n",
    "print(f\"Minimal value: {query_vector.min()}\")\n",
    "print(f\"Maximal value: {query_vector.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q2-title",
   "metadata": {},
   "source": [
    "## Q2. Cosine similarity with another vector\n",
    "\n",
    "The vectors that our embedding model returns are already normalized: their length is 1.0.\n",
    "\n",
    "You can check that by using the norm function:\n",
    "```python\n",
    "import numpy as np\n",
    "np.linalg.norm(q)\n",
    "```\n",
    "\n",
    "Which means that we can simply compute the dot product between two vectors to learn the cosine similarity between them.\n",
    "\n",
    "For example, if you compute the cosine of the query vector with itself, the result will be 1.0:\n",
    "```python\n",
    "q.dot(q)\n",
    "```\n",
    "\n",
    "Now let's embed this document:\n",
    "```\n",
    "doc = 'Can I still join the course after the start date?'\n",
    "```\n",
    "\n",
    "What's the cosine similarity between the vector for the query and the vector for the document?\n",
    "\n",
    "Options:\n",
    "- 0.3\n",
    "- 0.5\n",
    "- 0.7\n",
    "- 0.9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "q2-solution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query vector norm: 1.0\n",
      "Query vector dot product with itself: 1.0\n",
      "\n",
      "Document: Can I still join the course after the start date?\n",
      "Document vector norm: 0.9999999999999999\n",
      "\n",
      "Cosine similarity between query and document: 0.9008528856818037\n"
     ]
    }
   ],
   "source": [
    "# Q2 Solution: Cosine similarity with another vector\n",
    "\n",
    "# First, let's verify that vectors are normalized\n",
    "print(f\"Query vector norm: {np.linalg.norm(query_vector)}\")\n",
    "print(f\"Query vector dot product with itself: {query_vector.dot(query_vector)}\")\n",
    "\n",
    "# Embed the document\n",
    "doc = 'Can I still join the course after the start date?'\n",
    "doc_embedding = list(embedding_model.embed([doc]))[0]\n",
    "doc_vector = np.array(doc_embedding)\n",
    "\n",
    "print(f\"\\nDocument: {doc}\")\n",
    "print(f\"Document vector norm: {np.linalg.norm(doc_vector)}\")\n",
    "\n",
    "# Compute cosine similarity (dot product since vectors are normalized)\n",
    "cosine_similarity = query_vector.dot(doc_vector)\n",
    "\n",
    "print(f\"\\nCosine similarity between query and document: {cosine_similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q3-title",
   "metadata": {},
   "source": [
    "## Q3. Ranking by cosine\n",
    "\n",
    "For Q3 and Q4 we will use these documents:\n",
    "\n",
    "```python\n",
    "documents = [\n",
    "    {'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
    "     'section': 'General course-related questions',\n",
    "     'question': 'Course - Can I still join the course after the start date?',\n",
    "     'course': 'data-engineering-zoomcamp'},\n",
    "    {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
    "     'section': 'General course-related questions',\n",
    "     'question': 'Course - Can I follow the course after it finishes?',\n",
    "     'course': 'data-engineering-zoomcamp'},\n",
    "    {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  \"Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon't forget to register in DataTalks.Club's Slack and join the channel.\",\n",
    "     'section': 'General course-related questions',\n",
    "     'question': 'Course - When will the course start?',\n",
    "     'course': 'data-engineering-zoomcamp'},\n",
    "    {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
    "     'section': 'General course-related questions',\n",
    "     'question': 'Course - What can I do before the course starts?',\n",
    "     'course': 'data-engineering-zoomcamp'},\n",
    "    {'text': 'Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository.',\n",
    "     'section': 'General course-related questions',\n",
    "     'question': 'How can we contribute to the course?',\n",
    "     'course': 'data-engineering-zoomcamp'}\n",
    "]\n",
    "```\n",
    "\n",
    "Compute the embeddings for the text field, and compute the cosine between the query vector and all the documents.\n",
    "\n",
    "What's the document index with the highest similarity? (Indexing starts from 0):\n",
    "\n",
    "Options:\n",
    "- 0\n",
    "- 1\n",
    "- 2\n",
    "- 3\n",
    "- 4\n",
    "\n",
    "**Hint:** if you put all the embeddings of the text field in one matrix V (a single 2-dimensional numpy array), then computing the cosine becomes a matrix multiplication: `V.dot(q)`\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "q3-solution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding documents...\n",
      "Document embeddings matrix shape: (5, 512)\n",
      "\n",
      "Query: I just discovered the course. Can I join now?\n",
      "\n",
      "Cosine similarities with documents:\n",
      "Document 0: 0.7630\n",
      "  Question: Course - Can I still join the course after the start date?\n",
      "  Text preview: Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, t...\n",
      "\n",
      "Document 1: 0.8182\n",
      "  Question: Course - Can I follow the course after it finishes?\n",
      "  Text preview: Yes, we will keep all the materials after the course finishes, so you can follow the course at your ...\n",
      "\n",
      "Document 2: 0.8085\n",
      "  Question: Course - When will the course start?\n",
      "  Text preview: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and ho...\n",
      "\n",
      "Document 3: 0.7133\n",
      "  Question: Course - What can I do before the course starts?\n",
      "  Text preview: You can start by installing and setting up all the dependencies and requirements:\n",
      "Google cloud accou...\n",
      "\n",
      "Document 4: 0.7304\n",
      "  Question: How can we contribute to the course?\n",
      "  Text preview: Star the repo! Share it with friends if you find it useful ❣️\n",
      "Create a PR if you see you can improve...\n",
      "\n",
      "Document with highest similarity:\n",
      "Index: 1\n",
      "Similarity: 0.8182\n",
      "Question: Course - Can I follow the course after it finishes?\n"
     ]
    }
   ],
   "source": [
    "# Q3 Solution: Ranking by cosine\n",
    "\n",
    "# Define the documents\n",
    "documents = [{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I still join the course after the start date?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I follow the course after it finishes?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - When will the course start?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - What can I do before the course starts?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'How can we contribute to the course?',\n",
    "  'course': 'data-engineering-zoomcamp'}]\n",
    "\n",
    "# Extract text from documents\n",
    "texts = [doc['text'] for doc in documents]\n",
    "\n",
    "# Embed all documents\n",
    "print(\"Embedding documents...\")\n",
    "document_embeddings = list(embedding_model.embed(texts))\n",
    "\n",
    "# Convert to numpy array matrix (V)\n",
    "V = np.array(document_embeddings)\n",
    "print(f\"Document embeddings matrix shape: {V.shape}\")\n",
    "\n",
    "# Compute cosine similarities using matrix multiplication\n",
    "cosine_similarities = V.dot(query_vector)\n",
    "\n",
    "print(f\"\\nQuery: {query}\")\n",
    "print(\"\\nCosine similarities with documents:\")\n",
    "for i, (doc, similarity) in enumerate(zip(documents, cosine_similarities)):\n",
    "    print(f\"Document {i}: {similarity:.4f}\")\n",
    "    print(f\"  Question: {doc['question']}\")\n",
    "    print(f\"  Text preview: {doc['text'][:100]}...\")\n",
    "    print()\n",
    "\n",
    "# Find the document with highest similarity\n",
    "max_similarity_index = np.argmax(cosine_similarities)\n",
    "max_similarity = cosine_similarities[max_similarity_index]\n",
    "\n",
    "print(f\"Document with highest similarity:\")\n",
    "print(f\"Index: {max_similarity_index}\")\n",
    "print(f\"Similarity: {max_similarity:.4f}\")\n",
    "print(f\"Question: {documents[max_similarity_index]['question']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q4-title",
   "metadata": {},
   "source": [
    "## Q4. Ranking by cosine, version two\n",
    "\n",
    "Now let's calculate a new field, which is a concatenation of question and text:\n",
    "\n",
    "```python\n",
    "full_text = doc['question'] + ' ' + doc['text']\n",
    "```\n",
    "\n",
    "Embed this field and compute the cosine between it and the query vector. What's the highest scoring document?\n",
    "\n",
    "Options:\n",
    "- 0\n",
    "- 1\n",
    "- 2\n",
    "- 3\n",
    "- 4\n",
    "\n",
    "Is it different from Q3? If yes, why?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "q4-solution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full text examples:\n",
      "Document 0: Course - Can I still join the course after the start date? Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, h...\n",
      "\n",
      "Document 1: Course - Can I follow the course after it finishes? Yes, we will keep all the materials after the course finishes, so you can follow the course at you...\n",
      "\n",
      "Document 2: Course - When will the course start? The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the cou...\n",
      "\n",
      "Document 3: Course - What can I do before the course starts? You can start by installing and setting up all the dependencies and requirements:\n",
      "Google cloud accoun...\n",
      "\n",
      "Document 4: How can we contribute to the course? Star the repo! Share it with friends if you find it useful ❣️\n",
      "Create a PR if you see you can improve the text or ...\n",
      "\n",
      "Embedding full texts...\n",
      "Full text embeddings matrix shape: (5, 512)\n",
      "\n",
      "Query: I just discovered the course. Can I join now?\n",
      "\n",
      "Cosine similarities with full text (question + text):\n",
      "Document 0: 0.8515\n",
      "  Question: Course - Can I still join the course after the start date?\n",
      "\n",
      "Document 1: 0.8437\n",
      "  Question: Course - Can I follow the course after it finishes?\n",
      "\n",
      "Document 2: 0.8408\n",
      "  Question: Course - When will the course start?\n",
      "\n",
      "Document 3: 0.7755\n",
      "  Question: Course - What can I do before the course starts?\n",
      "\n",
      "Document 4: 0.8086\n",
      "  Question: How can we contribute to the course?\n",
      "\n",
      "Document with highest similarity (full text):\n",
      "Index: 0\n",
      "Similarity: 0.8515\n",
      "Question: Course - Can I still join the course after the start date?\n",
      "\n",
      "=== Comparison with Q3 ===\n",
      "Q3 (text only) - Highest similarity index: 1\n",
      "Q4 (question + text) - Highest similarity index: 0\n",
      "\n",
      "✓ Results are DIFFERENT!\n",
      "Why: Including the 'question' field in the embedding provides more semantic context.\n",
      "The query 'I just discovered the course. Can I join now?' is semantically closer to some questions than just the text content.\n",
      "This shows that the question titles contain important semantic information for matching.\n"
     ]
    }
   ],
   "source": [
    "# Q4 Solution: Ranking by cosine, version two\n",
    "\n",
    "# Create full_text field by concatenating question and text\n",
    "full_texts = [doc['question'] + ' ' + doc['text'] for doc in documents]\n",
    "\n",
    "print(\"Full text examples:\")\n",
    "for i, full_text in enumerate(full_texts):\n",
    "    print(f\"Document {i}: {full_text[:150]}...\")\n",
    "    print()\n",
    "\n",
    "# Embed all full_text documents\n",
    "print(\"Embedding full texts...\")\n",
    "full_text_embeddings = list(embedding_model.embed(full_texts))\n",
    "\n",
    "# Convert to numpy array matrix\n",
    "V_full = np.array(full_text_embeddings)\n",
    "print(f\"Full text embeddings matrix shape: {V_full.shape}\")\n",
    "\n",
    "# Compute cosine similarities using matrix multiplication\n",
    "cosine_similarities_full = V_full.dot(query_vector)\n",
    "\n",
    "print(f\"\\nQuery: {query}\")\n",
    "print(\"\\nCosine similarities with full text (question + text):\")\n",
    "for i, (doc, similarity) in enumerate(zip(documents, cosine_similarities_full)):\n",
    "    print(f\"Document {i}: {similarity:.4f}\")\n",
    "    print(f\"  Question: {doc['question']}\")\n",
    "    print()\n",
    "\n",
    "# Find the document with highest similarity\n",
    "max_similarity_index_full = np.argmax(cosine_similarities_full)\n",
    "max_similarity_full = cosine_similarities_full[max_similarity_index_full]\n",
    "\n",
    "print(f\"Document with highest similarity (full text):\")\n",
    "print(f\"Index: {max_similarity_index_full}\")\n",
    "print(f\"Similarity: {max_similarity_full:.4f}\")\n",
    "print(f\"Question: {documents[max_similarity_index_full]['question']}\")\n",
    "\n",
    "# Compare with Q3 results\n",
    "print(f\"\\n=== Comparison with Q3 ===\")\n",
    "print(f\"Q3 (text only) - Highest similarity index: {max_similarity_index}\")\n",
    "print(f\"Q4 (question + text) - Highest similarity index: {max_similarity_index_full}\")\n",
    "\n",
    "if max_similarity_index != max_similarity_index_full:\n",
    "    print(f\"\\n✓ Results are DIFFERENT!\")\n",
    "    print(f\"Why: Including the 'question' field in the embedding provides more semantic context.\")\n",
    "    print(f\"The query '{query}' is semantically closer to some questions than just the text content.\")\n",
    "    print(f\"This shows that the question titles contain important semantic information for matching.\")\n",
    "else:\n",
    "    print(f\"\\n✓ Results are the SAME!\")\n",
    "    print(f\"The same document had the highest similarity in both approaches.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q5-title",
   "metadata": {},
   "source": [
    "## Q5. Selecting the embedding model\n",
    "\n",
    "Now let's select a smaller embedding model. What's the smallest dimensionality for models in fastembed?\n",
    "\n",
    "Options:\n",
    "- 128\n",
    "- 256\n",
    "- 384\n",
    "- 512\n",
    "\n",
    "One of these models is `BAAI/bge-small-en`. Let's use it.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "q5-solution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique dimensions available: [384, 512, 768, 1024]\n",
      "Smallest dimension: 384\n",
      "\n",
      "Looking for BAAI/bge-small-en model:\n",
      "Found: BAAI/bge-small-en\n",
      "Dimension: 384\n",
      "Description: Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2023 year.\n",
      "Found: BAAI/bge-small-en-v1.5\n",
      "Dimension: 384\n",
      "Description: Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.\n",
      "\n",
      "Using model for Q6: BAAI/bge-small-en\n"
     ]
    }
   ],
   "source": [
    "# Q5 Solution: Selecting the embedding model\n",
    "\n",
    "# List all supported models and find their dimensions\n",
    "import json\n",
    "\n",
    "dimensions = []\n",
    "for model in TextEmbedding.list_supported_models():\n",
    "    dim = model['dim']\n",
    "    dimensions.append(dim)\n",
    "\n",
    "# Find the smallest dimension\n",
    "unique_dims = sorted(set(dimensions))\n",
    "print(f\"\\nUnique dimensions available: {unique_dims}\")\n",
    "print(f\"Smallest dimension: {min(unique_dims)}\")\n",
    "\n",
    "# Look specifically for BAAI/bge-small-en\n",
    "print(f\"\\nLooking for BAAI/bge-small-en model:\")\n",
    "for model in TextEmbedding.list_supported_models():\n",
    "    if 'bge-small-en' in model['model']:\n",
    "        print(f\"Found: {model['model']}\")\n",
    "        print(f\"Dimension: {model['dim']}\")\n",
    "        print(f\"Description: {model['description']}\")\n",
    "        \n",
    "# Initialize the smaller model for Q6\n",
    "small_model_name = \"BAAI/bge-small-en\"\n",
    "print(f\"\\nUsing model for Q6: {small_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q6-title",
   "metadata": {},
   "source": [
    "## Q6. Indexing with qdrant (2 points)\n",
    "\n",
    "For the last question, we will use more documents.\n",
    "\n",
    "We will select only FAQ records from our ml zoomcamp:\n",
    "\n",
    "```python\n",
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "    if course_name != 'machine-learning-zoomcamp':\n",
    "        continue\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "```\n",
    "\n",
    "Add them to qdrant using the model from Q5.\n",
    "\n",
    "When adding the data, use both question and answer fields:\n",
    "```python\n",
    "text = doc['question'] + ' ' + doc['text']\n",
    "```\n",
    "\n",
    "After the data is inserted, use the question from Q1 for querying the collection.\n",
    "\n",
    "What's the highest score in the results? (The score for the first returned record):\n",
    "\n",
    "Options:\n",
    "- 0.97\n",
    "- 0.87\n",
    "- 0.77\n",
    "- 0.67\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "q6-solution",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files:  20%|███████████████████████████████▏                                                                                                                            | 1/5 [00:03<00:15,  3.78s/it]Error while downloading from https://cdn-lfs-us-1.hf.co/repos/56/a7/56a7d32f4f0f1d04669581922991bf8b54943188f120a00956999d4e44993002/904dc556aacd699d056bcb46dec7535551ac876da69814baf0edc8fa0d184f4f?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model_optimized.onnx%3B+filename%3D%22model_optimized.onnx%22%3B&Expires=1750649901&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MDY0OTkwMX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzU2L2E3LzU2YTdkMzJmNGYwZjFkMDQ2Njk1ODE5MjI5OTFiZjhiNTQ5NDMxODhmMTIwYTAwOTU2OTk5ZDRlNDQ5OTMwMDIvOTA0ZGM1NTZhYWNkNjk5ZDA1NmJjYjQ2ZGVjNzUzNTU1MWFjODc2ZGE2OTgxNGJhZjBlZGM4ZmEwZDE4NGY0Zj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=e7MPQ4Vk%7EKcLy7aXd9YhjVq-1IFQt05wUCnbcwZqFrDbAE5uRby5PdF3arTEmxT8PKCuYuNLysPTmYiPb3BaNBag%7E7CLVKihIesaR2VVSroTJSlvY%7EmRdyz71c8SUssVGcz3NShgDP15%7ErnFVuLnyBQwTxkEM9Gc4xiYbO5eHgJi6NL4VT4UljvyA2K6Zx8g9qLA9y2xD3gqmUErQ494Ltfrsar6hZgD4MIw08Ly5lXzgYbLJ-lScBWUM%7ES4sNA549vL%7EMIblKTVziQhbdr5NYxLrn8C4oM5HZBuzyYLUZAZeI3zoP4-TsaAOGpE0Gu2bxlh10OWG3XVYBah2QiyQw__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Fetching 5 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:41<00:00, 20.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: BAAI/bge-small-en\n",
      "Model dimension: 384\n",
      "\\nFound 375 machine learning zoomcamp documents\n",
      "Deleted existing collection: ml-zoomcamp-homework\n",
      "Created collection: ml-zoomcamp-homework\n",
      "\\nPrepared 375 points for insertion\n",
      "Inserting points into Qdrant...\n",
      "✓ Points inserted successfully\n",
      "\\nQuerying with: 'I just discovered the course. Can I join now?'\n",
      "\\nSearch results:\n",
      "==================================================\n",
      "Rank 1:\n",
      "  Score: 0.8703\n",
      "  Question: The course has already started. Can I still join it?\n",
      "  Course: machine-learning-zoomcamp\n",
      "  Text preview: Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the ...\n",
      "\n",
      "Rank 2:\n",
      "  Score: 0.8692\n",
      "  Question: How long is the course?\n",
      "  Course: machine-learning-zoomcamp\n",
      "  Text preview: Approximately 4 months, but may take more if you want to do some extra activities (an extra project,...\n",
      "\n",
      "Rank 3:\n",
      "  Score: 0.8683\n",
      "  Question: I’m new to Slack and can’t find the course channel. Where is it?\n",
      "  Course: machine-learning-zoomcamp\n",
      "  Text preview: Here’s how you join a in Slack: https://slack.com/help/articles/205239967-Join-a-channel\n",
      "Click “All ...\n",
      "\n",
      "Rank 4:\n",
      "  Score: 0.8576\n",
      "  Question: How to get started with Week 10?\n",
      "  Course: machine-learning-zoomcamp\n",
      "  Text preview: TODO...\n",
      "\n",
      "Rank 5:\n",
      "  Score: 0.8572\n",
      "  Question: I just joined. What should I do next? How can I access course materials?\n",
      "  Course: machine-learning-zoomcamp\n",
      "  Text preview: Welcome to the course! Go to the course page (http://mlzoomcamp.com/), scroll down and start going t...\n",
      "\n",
      "Highest score (first returned record): 0.8703\n",
      "Closest option: 0.87\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "# Initialize smaller embedding model from Q5\n",
    "small_embedding_model = TextEmbedding(small_model_name)\n",
    "\n",
    "# Get the dimension of the smaller model\n",
    "small_model_info = None\n",
    "for model in TextEmbedding.list_supported_models():\n",
    "    if model['model'] == small_model_name:\n",
    "        small_model_info = model\n",
    "        break\n",
    "\n",
    "SMALL_EMBEDDING_DIMENSIONALITY = small_model_info['dim']\n",
    "\n",
    "# Fetch documents\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "# Filter only machine-learning-zoomcamp documents\n",
    "ml_documents = []\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "    if course_name != 'machine-learning-zoomcamp':\n",
    "        continue\n",
    "    \n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        ml_documents.append(doc)\n",
    "\n",
    "print(f\"\\\\nFound {len(ml_documents)} machine learning zoomcamp documents\")\n",
    "\n",
    "# Initialize Qdrant client\n",
    "client = QdrantClient(\"http://localhost:6333\")\n",
    "\n",
    "# Create new collection for Q6\n",
    "collection_name_q6 = \"ml-zoomcamp-homework\"\n",
    "\n",
    "# Delete collection if it exists (for clean start)\n",
    "try:\n",
    "    client.delete_collection(collection_name_q6)\n",
    "    print(f\"Deleted existing collection: {collection_name_q6}\")\n",
    "except:\n",
    "    print(f\"Collection {collection_name_q6} doesn't exist, creating new one\")\n",
    "\n",
    "# Create the collection\n",
    "client.create_collection(\n",
    "    collection_name=collection_name_q6,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=SMALL_EMBEDDING_DIMENSIONALITY,\n",
    "        distance=models.Distance.COSINE\n",
    "    )\n",
    ")\n",
    "\n",
    "# Prepare points for insertion\n",
    "points = []\n",
    "for i, doc in enumerate(ml_documents):\n",
    "    # Concatenate question and text\n",
    "    full_text = doc['question'] + ' ' + doc['text']\n",
    "    \n",
    "    point = models.PointStruct(\n",
    "        id=i,\n",
    "        vector=models.Document(text=full_text, model=small_model_name),\n",
    "        payload={\n",
    "            \"text\": doc['text'],\n",
    "            \"section\": doc['section'],\n",
    "            \"question\": doc['question'], \n",
    "            \"course\": doc['course'],\n",
    "            \"full_text\": full_text\n",
    "        }\n",
    "    )\n",
    "    points.append(point)\n",
    "\n",
    "# Insert points\n",
    "print(\"Inserting points into Qdrant...\")\n",
    "client.upsert(\n",
    "    collection_name=collection_name_q6,\n",
    "    points=points\n",
    ")\n",
    "print(\"✓ Points inserted successfully\")\n",
    "\n",
    "# Query using the question from Q1\n",
    "query_q1 = \"I just discovered the course. Can I join now?\"\n",
    "print(f\"\\\\nQuerying with: '{query_q1}'\")\n",
    "\n",
    "# Search in the collection\n",
    "search_results = client.query_points(\n",
    "    collection_name=collection_name_q6,\n",
    "    query=models.Document(\n",
    "        text=query_q1,\n",
    "        model=small_model_name\n",
    "    ),\n",
    "    limit=5,\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "# Get the highest score (first result)\n",
    "highest_score = search_results.points[0].score\n",
    "print(f\"Highest score (first returned record): {highest_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e773de35-a0c5-454c-95d0-7d3c539e3ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uv: .venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
